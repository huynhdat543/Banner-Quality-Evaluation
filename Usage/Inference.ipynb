{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_cTGSpD4qDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad55d3a0-e1c1-4b55-9722-5d1412e54ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_b0\n",
        "from PIL import Image, ImageSequence\n",
        "import timm\n",
        "from timm import create_model\n",
        "import os\n",
        "from torchvision import transforms, models\n",
        "from transformers import CLIPProcessor, CLIPVisionModel\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n"
      ],
      "metadata": {
        "id": "ULdOfjcTMkt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constrast"
      ],
      "metadata": {
        "id": "goUuOIiUWiYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Định nghĩa lại RegressionHead (phải giống hệt lúc train)\n",
        "class RegressionHead_Contrast(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 2. Hàm khởi tạo model và load weight\n",
        "def load_trained_contrast_model(model_path, device):\n",
        "    # Khởi tạo base model EfficientNet_B0\n",
        "    model = models.efficientnet_b0()\n",
        "\n",
        "    # Thay thế classifier bằng RegressionHead của bạn\n",
        "    in_dim = model.classifier[1].in_features # 1280\n",
        "    model.classifier = RegressionHead_Contrast(in_dim)\n",
        "\n",
        "    # Load trọng số đã lưu\n",
        "    state_dict = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval() # Chuyển sang chế độ dự báo\n",
        "    return model\n",
        "\n",
        "# 3. Tiền xử lý ảnh (phải giống lúc train)\n",
        "def preprocess_image_constrast(image_path):\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Xử lý nếu là ảnh GIF hoặc ảnh có kênh Alpha (RGBA)\n",
        "    if getattr(img, \"is_animated\", False):\n",
        "        img = ImageSequence.Iterator(img).__next__()\n",
        "    img = img.convert(\"RGBA\").convert(\"RGB\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    return transform(img).unsqueeze(0) # Thêm dimension cho batch (1, 3, 224, 224)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GnlSJ1ri4zTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Readability"
      ],
      "metadata": {
        "id": "UW1r16eHWlYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Định nghĩa các thành phần kiến trúc (Phải trùng khớp hoàn toàn với lúc train)\n",
        "class ResizeWithPadding:\n",
        "    def __init__(self, target_size, fill_color=(0, 0, 0)):\n",
        "        if isinstance(target_size, int):\n",
        "            self.target_size = (target_size, target_size)\n",
        "        else:\n",
        "            self.target_size = target_size\n",
        "        self.fill_color = fill_color\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img.thumbnail(self.target_size, Image.Resampling.BICUBIC)\n",
        "        new_img = Image.new(\"RGB\", self.target_size, self.fill_color)\n",
        "        left = (self.target_size[0] - img.size[0]) // 2\n",
        "        top = (self.target_size[1] - img.size[1]) // 2\n",
        "        new_img.paste(img, (left, top))\n",
        "        return new_img\n",
        "\n",
        "class ConvNeXtV2FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = create_model(\n",
        "            'convnextv2_tiny.fcmae_ft_in22k_in1k',\n",
        "            pretrained=False, # Không cần tải lại pretrain vì sẽ load từ file .pth\n",
        "            num_classes=0\n",
        "        )\n",
        "        self.feature_dim = 768\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "class ReadabilityRegressionHead(nn.Module):\n",
        "    def __init__(self, in_features=768):\n",
        "        super().__init__()\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(in_features),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.head(x)\n",
        "\n",
        "class CompleteReadabilityModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = ConvNeXtV2FeatureExtractor()\n",
        "        self.head = ReadabilityRegressionHead(in_features=768)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return self.head(features)\n",
        "\n",
        "# 2. Tiền xử lý ảnh (Theo logic trong BannerDataset của bạn)\n",
        "def preprocess_image_readability(image_path, target_size=224):\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Xử lý GIF\n",
        "    if getattr(img, \"is_animated\", False):\n",
        "        img = ImageSequence.Iterator(img).__next__()\n",
        "\n",
        "    # Chuyển nền trong suốt thành trắng (Logic quan trọng từ code của bạn)\n",
        "    img = img.convert(\"RGBA\")\n",
        "    background = Image.new('RGBA', img.size, (255, 255, 255))\n",
        "    img = Image.alpha_composite(background, img)\n",
        "    img = img.convert(\"RGB\")\n",
        "\n",
        "    # Transform với Padding\n",
        "    transform = transforms.Compose([\n",
        "        ResizeWithPadding(target_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    return transform(img).unsqueeze(0)\n",
        "\n",
        "def load_trained_readability_model(model_path, device):\n",
        "    model_readability = CompleteReadabilityModel().to(device)\n",
        "    # Kiểm tra nếu load từ checkpoint (có chứa dict) hay state_dict thuần túy\n",
        "    checkpoint = torch.load(model_path[1], map_location=device)\n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        model_readability.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        model_readability.load_state_dict(checkpoint)\n",
        "    model_readability.eval()\n",
        "\n",
        "    return model_readability\n"
      ],
      "metadata": {
        "id": "5Vsxr6TwDyLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aesthetic"
      ],
      "metadata": {
        "id": "Eo7qEHSNWq_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AestheticPredictor(nn.Module):\n",
        "    def __init__(self, model_name=\"openai/clip-vit-base-patch32\", dropout=0.2):\n",
        "        super(AestheticPredictor, self).__init__()\n",
        "        # Load CLIP Backbone\n",
        "        self.backbone = CLIPVisionModel.from_pretrained(model_name)\n",
        "\n",
        "        # Config khớp với lúc train\n",
        "        self.hidden_size = self.backbone.config.hidden_size\n",
        "\n",
        "        # MLP Head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.backbone(pixel_values=x)\n",
        "        features = out.pooler_output\n",
        "        return self.head(features)\n",
        "\n",
        "def load_trained_aesthetic_model(model_path, model_name=\"openai/clip-vit-base-patch32\", device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Khởi tạo kiến trúc và load trọng số đã train\n",
        "    \"\"\"\n",
        "    print(f\" Đang khởi tạo model base: {model_name}...\")\n",
        "    model = AestheticPredictor(model_name=model_name)\n",
        "\n",
        "    print(f\" Đang load trọng số từ: {model_path}...\")\n",
        "    # map_location giúp load model train bằng GPU lên máy chỉ có CPU mà không bị lỗi\n",
        "    state_dict = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval() # Chuyển sang chế độ đánh giá (tắt Dropout)\n",
        "\n",
        "    # Load processor đi kèm (để resize/normalize ảnh đúng chuẩn)\n",
        "    processor = CLIPProcessor.from_pretrained(model_name)\n",
        "\n",
        "    return model, processor\n",
        "\n"
      ],
      "metadata": {
        "id": "FUo_VbSkPeRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "WxqTNMs_Wvje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_path, model_path):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Khởi tạo và load model readibility\n",
        "    model_readability = load_trained_readability_model(model_path, device)\n",
        "\n",
        "    # Khởi tạo và load model contrast\n",
        "    model_contrast = load_trained_contrast_model(model_path[0], device)\n",
        "\n",
        "    # Khởi tạo và load model Aesthetic\n",
        "    model_aesthetic, processor = load_trained_aesthetic_model(model_path[2], device=device)\n",
        "\n",
        "    # Load và xử lý ảnh\n",
        "    input_tensor_contrast = preprocess_image_constrast(image_path).to(device)\n",
        "    input_tensor_readability = preprocess_image_readability(image_path, target_size=224).to(device)\n",
        "    input_tensor_aesthetic = processor(images=Image.open(image_path), return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Dự đoán\n",
        "    with torch.no_grad():\n",
        "        score_readability = model_readability(input_tensor_readability)\n",
        "        score_contrast = model_contrast(input_tensor_contrast)\n",
        "        score_aesthetic = model_aesthetic(input_tensor_aesthetic['pixel_values'])\n",
        "\n",
        "    return score_readability.item(), score_contrast.item(), score_aesthetic.item()"
      ],
      "metadata": {
        "id": "bg9CRERmRxar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recommend(model_geminai,readability_score, aesthetic_score, contrast_score):\n",
        "  prompt = f'''\n",
        "Các tiêu chí chấm điểm về độ thẩm mỹ, độ dễ đọc, độ tương phản cho 1 tấm banner quảng cáo :\n",
        "Tiêu chí về độ thẩm mỹ\n",
        "5 (Xuất Sắc): \"Thiết kế rất chuyên nghiệp, sáng tạo, bố cục hoàn hảo, màu sắc hài hòa, sử dụng hình ảnh chất lượng cao. Tạo ấn tượng thị giác mạnh mẽ.\",Thẩm mỹ cao/Rất chuyên nghiệp\n",
        "4 (Tốt): \"Thiết kế chuyên nghiệp, thu hút, bố cục rõ ràng, màu sắc dễ chịu. Có thể có một vài chi tiết nhỏ chưa tối ưu nhưng tổng thể rất tốt.\",Thẩm mỹ tốt/Chuyên nghiệp\n",
        "3 (Trung Bình): \"Thiết kế chấp nhận được, không quá ấn tượng, bố cục cơ bản. Có thể có lỗi nhỏ về màu sắc hoặc chất lượng hình ảnh không đồng đều.\",Thẩm mỹ trung bình/Cơ bản\n",
        "2 (Kém): \"Thiết kế sơ sài, thiếu đầu tư, bố cục lộn xộn hoặc nhàm chán, màu sắc không hài hòa. Hình ảnh/font chữ kém chất lượng.\",Thẩm mỹ kém/Thiếu chuyên nghiệp\n",
        "1 (Rất Kém): \"Thiết kế tồi tệ, các yếu tố xung đột nhau, màu sắc chói mắt/xấu xí, bố cục không hợp lý, gây khó chịu khi nhìn.\",Thẩm mỹ rất kém/Lỗi thiết kế\n",
        "\n",
        "Tiêu chí về độ dễ đọc\n",
        "5 (Xuất Sắc) : Tất cả văn bản có kích thước và kiểu chữ rất dễ đọc ngay cả khi nhìn thoáng qua. Khoảng cách chữ/dòng hoàn hảo.,Dễ đọc hoàn hảo\n",
        "4 (Tốt): Phần lớn văn bản dễ đọc. Chỉ có thể có một vài đoạn văn bản phụ (phụ chú) có kích thước hơi nhỏ nhưng vẫn có thể đọc được.,Dễ đọc tốt\n",
        "3 (Trung Bình) : \"Văn bản chủ yếu dễ đọc, nhưng một số phần quan trọng hoặc phần lớn văn bản phụ hơi nhỏ hoặc hơi khó đọc do chọn font/kích thước chưa hợp lý.\",Đọc được/Trung bình\n",
        "2 (Kém) : \"Phần lớn văn bản khó đọc do kích thước quá nhỏ, chọn font khó nhìn (quá cầu kỳ, nét mỏng) hoặc khoảng cách chữ quá sít sao.\",Khó đọc\n",
        "1 (Rất Kém) : Không thể đọc được nội dung chính hoặc phần lớn nội dung do font chữ/kích thước/vị trí bị lỗi hoặc chữ bị che khuất quá nhiều.,Rất khó đọc/Không đọc được\n",
        "\n",
        "Tiêu chí về độ tương phản\n",
        "Tiêu chí độ tương phản\n",
        "5 (Xuất Sắc) : Độ tương phản hoàn hảo và rõ rệt (ví dụ: chữ trắng trên nền tối đậm hoặc chữ đen trên nền sáng rực). Đảm bảo khả năng đọc tối đa.,Tương phản tối đa/Hoàn hảo\n",
        "4 (Tốt) : Độ tương phản rất tốt và rõ ràng. Màu chữ nổi bật so với màu nền.,Tương phản tốt\n",
        "3 (Trung Bình) : Độ tương phản vừa đủ để đọc. Văn bản có thể không nổi bật hoàn toàn (ví dụ: chữ xám trên nền trắng hoặc chữ xanh đậm trên nền tím) nhưng vẫn chấp nhận được.,Tương phản đủ dùng\n",
        "2 (Kém) : \"Độ tương phản thấp, gây mỏi mắt hoặc phải căng mắt để đọc (ví dụ: chữ xanh dương nhạt trên nền xanh lá nhạt). Gây khó khăn đáng kể cho việc đọc.\",Tương phản thấp\n",
        "1 (Rất Kém) : \"Không có sự tương phản hoặc rất ít (ví dụ: chữ vàng nhạt trên nền trắng/vàng nhạt). Văn bản hầu như hòa vào nền, không thể đọc được.\",Không tương phản/Hòa vào nền\n",
        "\n",
        "Nhiệm vụ : Đây lần lượt là điểm về tiêu chí thẩm mỹ {aesthetic_score}, điểm về độ dễ đọc {readability_score} và điểm về độ tương phản {contrast_score} bạn nhận được. Dựa vào các tiêu chí về chấm điểm ở trên, đầu tiên hãy nhận xet, sau đó sinh ra câu gợi ý giúp tấm ảnh banner quảng cáo cải thiện hơn\n",
        "Quy tắc :\n",
        "- Chỉ dựa vào các tiêu chí tôi đã định nghĩa ở trên\n",
        "- Không trả lời rườm rà, lan man\n",
        "  '''\n",
        "  response = model_geminai.generate_content(prompt)\n",
        "  text = response.text\n",
        "  return text"
      ],
      "metadata": {
        "id": "hfhL_P_PF6Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yJ4iooyOH14d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Đường dẫn tới file model và ảnh của bạn\n",
        "    MODEL_FILE = [\"/content/drive/MyDrive/Deeplearning/Do_An/Đạt/model_effnet_45.pth\",\"/content/drive/MyDrive/Deeplearning/Do_An/best_readability_model.pth\",'/content/drive/MyDrive/Deeplearning/Do_An/my_finetuned_clip.pth']\n",
        "    IMAGE_FILE = \"/content/drive/MyDrive/Deeplearning/extracted_images/15.png\"\n",
        "    genai.configure(api_key=\"AIzaSyDzC772ZbPTrsr5_JSl0NRLRVE5PtME684\")\n",
        "    model_geminai = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "    if os.path.exists(IMAGE_FILE):\n",
        "        r,c,a = predict(IMAGE_FILE, MODEL_FILE)\n",
        "        print(f\"Dự đoán điểm tương phản (Contrast Score): {c:.2f}\")\n",
        "        print(f\"Dự đoán điểm độ dễ đọc (Readability Score): {r:.2f}\")\n",
        "        print(f\"Dự đoán điểm chất lượng (Aesthetic Score): {a:.2f}\")\n",
        "        print(f'Điểm tổng quát :{(r+c+a)/3:.2f}')\n",
        "        print(f'Gợi ý :{generate_recommend(model_geminai,r,a,c)}')\n",
        "    else:\n",
        "        print(\"Vui lòng kiểm tra lại đường dẫn file model hoặc file ảnh!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "K_YPa5xHDVVK",
        "outputId": "ba9f1e33-af68-4560-8902-792e512fda75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Đang khởi tạo model base: openai/clip-vit-base-patch32...\n",
            " Đang load trọng số từ: /content/drive/MyDrive/Deeplearning/Do_An/my_finetuned_clip.pth...\n",
            "Dự đoán điểm tương phản (Contrast Score): 3.19\n",
            "Dự đoán điểm độ dễ đọc (Readability Score): 2.58\n",
            "Dự đoán điểm chất lượng (Aesthetic Score): 2.69\n",
            "Điểm tổng quát :2.82\n",
            "Gợi ý :**Nhận xét:**\n",
            "\n",
            "*   **Độ thẩm mỹ (2.685):** Thiết kế ở mức chấp nhận được, nhưng chưa ấn tượng, bố cục còn cơ bản và có thể có lỗi nhỏ về màu sắc hoặc chất lượng hình ảnh chưa đồng đều. Gần với mức kém, cho thấy thiết kế có thể còn sơ sài, thiếu đầu tư.\n",
            "*   **Độ dễ đọc (2.578):** Văn bản chủ yếu khó đọc do kích thước có thể quá nhỏ, chọn font khó nhìn hoặc khoảng cách chữ quá sít sao. Một số phần quan trọng hoặc phần lớn văn bản phụ hơi nhỏ hoặc khó đọc.\n",
            "*   **Độ tương phản (3.189):** Độ tương phản vừa đủ để đọc nhưng văn bản chưa thực sự nổi bật hoàn toàn so với nền, mặc dù vẫn chấp nhận được.\n",
            "\n",
            "**Gợi ý cải thiện:**\n",
            "\n",
            "*   **Thẩm mỹ:** Cải thiện bố cục để rõ ràng và thu hút hơn, chọn màu sắc hài hòa, và đầu tư vào hình ảnh/font chữ chất lượng cao để tạo ấn tượng thị giác mạnh mẽ.\n",
            "*   **Độ dễ đọc:** Chọn font chữ rõ ràng, dễ đọc, điều chỉnh kích thước văn bản phù hợp (đặc biệt là các phần phụ) và tối ưu khoảng cách chữ/dòng để đảm bảo tất cả văn bản dễ đọc ngay cả khi nhìn thoáng qua.\n",
            "*   **Độ tương phản:** Tăng cường độ tương phản giữa chữ và nền để văn bản nổi bật hơn, ưu tiên các cặp màu tương phản mạnh (ví dụ: chữ sáng trên nền tối hoặc chữ tối trên nền sáng) nhằm tối đa hóa khả năng đọc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2qhrSviAJiQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}